<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quick Speech Test</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        .section { margin: 20px 0; padding: 20px; border: 1px solid #ddd; border-radius: 8px; }
        button { background: #007acc; color: white; border: none; padding: 10px 20px; border-radius: 4px; cursor: pointer; margin: 5px; }
        .result { background: #f5f5f5; padding: 15px; border-radius: 4px; margin: 10px 0; white-space: pre-wrap; font-family: monospace; }
        .error { background: #ffe6e6; border-left: 4px solid #ff0000; }
        .success { background: #e6ffe6; border-left: 4px solid #00ff00; }
    </style>
</head>
<body>
    <h1>🔬 Quick Speech Recognition Test</h1>
    
    <div class="section">
        <h2>🎯 Test 1: Azure Configuration Check</h2>
        <button onclick="testAzureConfig()">Test Azure Setup</button>
        <div id="configResult" class="result" style="display: none;"></div>
    </div>

    <div class="section">
        <h2>🎤 Test 2: Record Simple Audio</h2>
        <p>Record yourself saying: <strong>"Hello world"</strong></p>
        <button id="recordBtn" onclick="toggleRecording()">🔴 Start Recording</button>
        <button id="testRecordBtn" onclick="testRecording()" style="display: none;">🎯 Test Recording</button>
        <audio id="recordedAudio" controls style="display: none; width: 100%; margin: 10px 0;"></audio>
        <div id="recordResult" class="result" style="display: none;"></div>
    </div>

    <div class="section">
        <h2>📁 Test 3: Upload Audio File</h2>
        <input type="file" id="audioFile" accept=".mp3,.wav,.m4a" />
        <button onclick="testUploadedFile()">🎯 Test Uploaded File</button>
        <button onclick="convertAndTestFile()">🔄 Convert to Mono & Test</button>
        <div id="uploadResult" class="result" style="display: none;"></div>
    </div>

    <div class="section">
        <h2>🔧 Audio Format Info</h2>
        <p><strong>Current Issue:</strong> Azure Speech Services works best with <strong>mono audio</strong> (single channel).</p>
        <p><strong>Your audio might be stereo</strong> which can cause recognition failures.</p>
        <button onclick="checkAudioFormat()">📊 Check Last Uploaded File Format</button>
        <div id="formatResult" class="result" style="display: none;"></div>
    </div>

    <script>
        let mediaRecorder;
        let recordedBlob = null;
        let isRecording = false;

        async function testAzureConfig() {
            const resultDiv = document.getElementById('configResult');
            resultDiv.style.display = 'block';
            resultDiv.innerHTML = '🔄 Testing Azure configuration...\n';

            try {
                // Test with minimal empty request to check Azure keys
                const response = await fetch('/api/speech-to-text', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({}) // Empty request to trigger validation
                });

                const result = await response.json();
                
                if (result.error === 'Azure Speech Service configuration missing') {
                    resultDiv.className = 'result error';
                    resultDiv.innerHTML = `❌ AZURE CONFIGURATION PROBLEM

Error: ${result.error}
Details: ${result.details}

🔧 SOLUTION NEEDED:
1. Go to Azure Portal
2. Navigate to your Static Web App
3. Go to Configuration > Application Settings
4. Add these environment variables:
   - AZURE_SPEECH_KEY: (your speech service key)
   - AZURE_SPEECH_REGION: (your speech service region)

Debug Info: ${JSON.stringify(result.debug, null, 2)}`;
                } else if (result.error === 'Missing audio data') {
                    resultDiv.className = 'result success';
                    resultDiv.innerHTML = `✅ AZURE CONFIGURATION IS WORKING!

The API responded correctly to the test request.
Azure Speech Service keys are properly configured.

Next step: Test with actual audio data.`;
                } else {
                    resultDiv.className = 'result error';
                    resultDiv.innerHTML = `⚠️ UNEXPECTED RESPONSE:

${JSON.stringify(result, null, 2)}`;
                }

            } catch (error) {
                resultDiv.className = 'result error';
                resultDiv.innerHTML = `❌ API CONNECTION FAILED

Error: ${error.message}

🔧 POSSIBLE CAUSES:
1. Azure Function is not deployed
2. Network connectivity issues
3. API endpoint is incorrect
4. Azure Function is not running`;
            }
        }

        async function toggleRecording() {
            if (!isRecording) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);
                    const chunks = [];

                    mediaRecorder.ondataavailable = (event) => chunks.push(event.data);
                    mediaRecorder.onstop = () => {
                        recordedBlob = new Blob(chunks, { type: 'audio/wav' });
                        const audioURL = URL.createObjectURL(recordedBlob);
                        
                        const audioElement = document.getElementById('recordedAudio');
                        audioElement.src = audioURL;
                        audioElement.style.display = 'block';
                        
                        document.getElementById('testRecordBtn').style.display = 'inline-block';
                        
                        const resultDiv = document.getElementById('recordResult');
                        resultDiv.style.display = 'block';
                        resultDiv.className = 'result';
                        resultDiv.innerHTML = `✅ Recording complete! (${(recordedBlob.size / 1024).toFixed(1)} KB)\n\nClick "Test Recording" to test speech recognition.`;
                    };

                    mediaRecorder.start();
                    isRecording = true;
                    document.getElementById('recordBtn').innerHTML = '⏹️ Stop Recording (say "Hello world")';
                    
                } catch (error) {
                    alert('Microphone access denied: ' + error.message);
                }
            } else {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                document.getElementById('recordBtn').innerHTML = '🔴 Start Recording';
            }
        }

        async function testRecording() {
            if (!recordedBlob) {
                alert('No recording available');
                return;
            }

            await testAudioBlob(recordedBlob, 'recordResult', 'Recorded Audio');
        }

        async function testUploadedFile() {
            const fileInput = document.getElementById('audioFile');
            const file = fileInput.files[0];
            
            if (!file) {
                alert('Please select a file first');
                return;
            }

            await testAudioBlob(file, 'uploadResult', 'Uploaded File (Original)');
        }

        async function convertAndTestFile() {
            const fileInput = document.getElementById('audioFile');
            const file = fileInput.files[0];
            
            if (!file) {
                alert('Please select a file first');
                return;
            }

            const resultDiv = document.getElementById('uploadResult');
            resultDiv.style.display = 'block';
            resultDiv.className = 'result';
            resultDiv.innerHTML = '🔄 Converting audio to mono format...\n';

            try {
                const monoBlob = await convertToMono(file);
                resultDiv.innerHTML += `✅ Converted to mono! Original: ${(file.size/1024).toFixed(1)}KB → Mono: ${(monoBlob.size/1024).toFixed(1)}KB\n\n`;
                await testAudioBlob(monoBlob, 'uploadResult', 'Uploaded File (Converted to Mono)');
            } catch (error) {
                resultDiv.className = 'result error';
                resultDiv.innerHTML += `❌ Conversion failed: ${error.message}\n\nTrying original file instead...\n\n`;
                await testAudioBlob(file, 'uploadResult', 'Uploaded File (Original - Conversion Failed)');
            }
        }

        async function checkAudioFormat() {
            const fileInput = document.getElementById('audioFile');
            const file = fileInput.files[0];
            
            if (!file) {
                alert('Please select a file first');
                return;
            }

            const resultDiv = document.getElementById('formatResult');
            resultDiv.style.display = 'block';
            resultDiv.className = 'result';
            resultDiv.innerHTML = '🔍 Analyzing audio format...\n';

            try {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const arrayBuffer = await file.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                const channels = audioBuffer.numberOfChannels;
                const sampleRate = audioBuffer.sampleRate;
                const duration = audioBuffer.duration;

                resultDiv.innerHTML = `📊 Audio Format Analysis:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📁 File: ${file.name}
📏 Size: ${(file.size / 1024 / 1024).toFixed(2)} MB
🎵 Format: ${file.type || 'Unknown'}
⏱️ Duration: ${duration.toFixed(2)} seconds

🔊 Audio Properties:
   • Channels: ${channels} ${channels === 1 ? '(MONO ✅)' : channels === 2 ? '(STEREO ⚠️)' : '(MULTI-CHANNEL ❌)'}
   • Sample Rate: ${sampleRate} Hz ${sampleRate === 16000 ? '(OPTIMAL ✅)' : sampleRate === 44100 ? '(GOOD ✓)' : '(⚠️)'}
   • Bit Depth: ~16-bit (estimated)

💡 Recommendations:
${channels === 1 ? '✅ Mono audio - should work well with Azure Speech' : '⚠️ Convert to MONO for better Azure Speech recognition'}
${sampleRate === 16000 ? '✅ Optimal sample rate for speech recognition' : '💡 16kHz sample rate is optimal for speech recognition'}

🎯 Action: ${channels === 1 && sampleRate === 16000 ? 'Your audio is already optimized!' : 'Try the "Convert to Mono & Test" button above'}`;

            } catch (error) {
                resultDiv.className = 'result error';
                resultDiv.innerHTML = `❌ Could not analyze audio format: ${error.message}

This might indicate:
• Unsupported audio format
• Corrupted audio file
• Browser compatibility issue

Try using a WAV file for best results.`;
            }
        }

        async function convertToMono(file) {
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            
            // Read and decode the audio file
            const arrayBuffer = await file.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // If already mono, return as-is
            if (audioBuffer.numberOfChannels === 1) {
                return file;
            }
            
            // Convert to mono by mixing channels
            const length = audioBuffer.length;
            const sampleRate = 16000; // Optimal for Azure Speech
            const numberOfChannels = 1; // Mono
            
            // Create offline context for processing
            const offlineContext = new OfflineAudioContext(numberOfChannels, Math.floor(length * sampleRate / audioBuffer.sampleRate), sampleRate);
            
            // Create buffer source
            const source = offlineContext.createBufferSource();
            source.buffer = audioBuffer;
            
            // Create channel merger to mix stereo to mono
            if (audioBuffer.numberOfChannels > 1) {
                const merger = offlineContext.createChannelMerger(1);
                const splitter = offlineContext.createChannelSplitter(audioBuffer.numberOfChannels);
                
                source.connect(splitter);
                
                // Mix all channels to mono
                for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                    const gainNode = offlineContext.createGain();
                    gainNode.gain.value = 1 / audioBuffer.numberOfChannels; // Equal mix
                    splitter.connect(gainNode, i);
                    gainNode.connect(merger, 0, 0);
                }
                
                merger.connect(offlineContext.destination);
            } else {
                source.connect(offlineContext.destination);
            }
            
            source.start();
            
            // Render the audio
            const renderedBuffer = await offlineContext.startRendering();
            
            // Convert to WAV blob
            return audioBufferToWav(renderedBuffer);
        }

        // Convert AudioBuffer to WAV blob (mono, 16kHz, 16-bit)
        function audioBufferToWav(buffer) {
            const length = buffer.length;
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);

            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };

            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true); // PCM
            view.setUint16(22, 1, true); // Mono
            view.setUint32(24, buffer.sampleRate, true);
            view.setUint32(28, buffer.sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);

            // Convert float samples to 16-bit PCM
            const channelData = buffer.getChannelData(0);
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }

            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }

        async function testAudioBlob(blob, resultDivId, testName) {
            const resultDiv = document.getElementById(resultDivId);
            resultDiv.style.display = 'block';
            resultDiv.className = 'result';
            resultDiv.innerHTML = `🔄 Testing ${testName}...\n`;

            try {
                // Convert to base64
                const base64 = await blobToBase64(blob);
                
                resultDiv.innerHTML += `📝 Audio converted to base64 (${base64.length} chars)\n`;
                resultDiv.innerHTML += `🌐 Sending to Azure Speech Service...\n`;

                const response = await fetch('/api/speech-to-text', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        audioData: base64,
                        format: blob.type || 'audio/wav'
                    })
                });

                const result = await response.json();

                if (result.success) {
                    resultDiv.className = 'result success';
                    resultDiv.innerHTML += `\n✅ SUCCESS! Speech recognized:\n\n`;
                    resultDiv.innerHTML += `🗣️ Text: "${result.text}"\n`;
                    resultDiv.innerHTML += `📊 Debug: ${JSON.stringify(result.debug, null, 2)}`;
                } else {
                    resultDiv.className = 'result error';
                    resultDiv.innerHTML += `\n❌ FAILED: ${result.error}\n\n`;
                    resultDiv.innerHTML += `📝 Details: ${result.details}\n\n`;
                    
                    if (result.debug) {
                        resultDiv.innerHTML += `🔍 Debug Information:\n`;
                        resultDiv.innerHTML += JSON.stringify(result.debug, null, 2) + '\n\n';
                    }
                    
                    if (result.troubleshooting) {
                        resultDiv.innerHTML += `💡 Suggestions:\n`;
                        result.troubleshooting.suggestions?.forEach((suggestion, i) => {
                            resultDiv.innerHTML += `   ${i + 1}. ${suggestion}\n`;
                        });
                    }
                }

            } catch (error) {
                resultDiv.className = 'result error';
                resultDiv.innerHTML += `\n❌ ERROR: ${error.message}`;
            }
        }

        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => {
                    const base64 = reader.result.split(',')[1];
                    resolve(base64);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }
    </script>
</body>
</html>
